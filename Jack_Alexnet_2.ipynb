{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jackschmell/Baseball-AI/blob/main/Jack_Alexnet_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LUaVnys1Qyuj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from google.colab import drive\n",
        "from torchsummary import summary "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Mount Google Drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# 2. Load labeled images from folders\n",
        "# data_dir = '/content/gdrive/MyDrive/Data2023/ballgame'\n",
        "data_dir = '/content/gdrive/MyDrive/Data2023/ballgame'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "854fa098-c0af-481d-e2b3-d73657dc8695",
        "id": "bZ7O0ihLQyuk"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Pre-process the data and create data loaders\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'valid': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}"
      ],
      "metadata": {
        "id": "viMy5KEnQyul"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_datasets = {x: datasets.ImageFolder(data_dir + '/' + x, data_transforms[x]) for x in ['train', 'valid']}\n",
        "dataloaders = {x: DataLoader(image_datasets[x], batch_size=16, shuffle=True, num_workers=4) for x in ['train', 'valid']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'valid']}\n",
        "class_names = image_datasets['train'].classes\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "L5uNetpjQyum",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7656fae-1928-41be-9517-31b42ee515d1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6E2RQpjcOWMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ek6fG5qvNsdD",
        "outputId": "6e87cdf1-db85-4e09-bc45-a58636598cf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1], Loss: 0.9566\n",
            "Epoch [2], Loss: 0.8735\n",
            "Epoch [3], Loss: 0.6814\n",
            "Epoch [4], Loss: 0.5138\n",
            "Epoch [5], Loss: 0.6925\n",
            "Epoch [6], Loss: 0.5052\n",
            "Epoch [7], Loss: 0.9486\n",
            "Epoch [8], Loss: 0.5215\n",
            "Epoch [9], Loss: 0.4533\n",
            "Epoch [10], Loss: 0.5107\n",
            "Accuracy of the network on the test images: 81 %\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "# Load the pre-trained AlexNet model\n",
        "alexnet = models.alexnet(pretrained=True)\n",
        "\n",
        "# Freeze the weights of the pre-trained model\n",
        "for param in alexnet.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Modify the last fully connected layer to match the number of pitch types in the dataset\n",
        "num_pitch_types = 2\n",
        "alexnet.classifier[6] = torch.nn.Linear(4096, num_pitch_types)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(alexnet.classifier.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(10):\n",
        "    running_loss = 0.0\n",
        "    for (inputs, labels) in dataloaders[\"train\"]:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = alexnet(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print('Epoch [%d], Loss: %.4f' % (epoch+1, running_loss / len(dataloaders[\"train\"])))\n",
        "\n",
        "# Test the model\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in dataloaders[\"valid\"]:\n",
        "        images, labels = data\n",
        "        outputs = alexnet(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Will Improve on accuracy hopefully ! (Include more and better data)\n"
      ],
      "metadata": {
        "id": "9YWycm16OocK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}